# Microcredential Creation Workshop - Instructor Walkthrough

**Comprehensive Guide for Facilitators**

---

## üìã Table of Contents

1. [Workshop Overview](#workshop-overview)
2. [Pre-Workshop Preparation](#pre-workshop-preparation)
3. [Detailed Step-by-Step Instructions](#detailed-step-by-step-instructions)
4. [Troubleshooting Guide](#troubleshooting-guide)
5. [Assessment Rubric](#assessment-rubric)
6. [Extension Activities](#extension-activities)
7. [Resources & Links](#resources--links)

---

## Workshop Overview

### Purpose

This workshop teaches students to create UNESCO-aligned microcredential courses using AI tools and LiaScript. Students will experience the complete workflow from research to deployment, developing both technical skills and critical AI literacy.

### Learning Outcomes

By the end of the workshop, students will be able to:

1. **Select and justify** a UNESCO AI Competency Framework learning objective appropriate for their teaching context
2. **Research and curate** academic resources using AI-powered tools (Consensus AI)
3. **Design and structure** a comprehensive course outline using generative AI (ChatGPT Deep Search)
4. **Create and deploy** an interactive LiaScript presentation using AI assistance (Claude)
5. **Document and reflect** critically on their AI-assisted design process

### Duration & Format

- **Total Time:** 90-120 minutes
- **Format:** Hands-on workshop with guided practice
- **Class Size:** 10-30 students (optimal: 15-20)
- **Delivery Mode:** In-person or synchronous online
- **Technical Requirements:** Computer with internet access per student

### The Complete Workflow

```
Step 1: Select UNESCO Learning Objective (10 min)
    ‚Üì
Step 2: Research with Consensus AI (20 min)
    ‚Üì
Step 3: Design Outline with ChatGPT (25 min)
    ‚Üì
Step 4: Build LiaScript with Claude (35 min)
    ‚Üì
Step 5: Test & Deploy (15 min)
    ‚Üì
Step 6: Document & Reflect (10 min)
```

---

## Pre-Workshop Preparation

### 1. Technical Setup (1 week before)

**Student Accounts to Create:**

- [ ] **Consensus AI** (https://consensus.app)
  - Free tier sufficient for workshop
  - Optional: Institutional access if available
  
- [ ] **ChatGPT** (https://chat.openai.com)
  - Free tier works, but Plus recommended for Deep Search
  - Ensure students can access ChatGPT in your location
  
- [ ] **Claude.ai** (https://claude.ai)
  - Free tier sufficient
  - Familiarize students with interface beforehand

- [ ] **GitHub** (https://github.com) - *Optional but recommended*
  - For permanent hosting and version control
  - Free accounts sufficient

**Platform Access:**

- [ ] **LiaScript LiveEditor** (https://liascript.github.io/LiveEditor/)
  - No account needed
  - Test accessibility in your network
  - Ensure browsers are up-to-date (Chrome, Firefox, Edge recommended)

### 2. Instructor Preparation (3-5 days before)

**Required Actions:**

1. **Complete the workflow yourself** with a sample learning objective
   - This gives you firsthand experience of potential issues
   - Creates a reference example to show students
   - Helps you estimate realistic timing

2. **Test all tools and platforms**
   - Verify tool availability in your institution's network
   - Check for firewalls or access restrictions
   - Test on both desktop and mobile if possible

3. **Prepare example materials**
   - 2-3 example UNESCO learning objectives
   - Sample Consensus AI search results
   - Example ChatGPT outline
   - Complete LiaScript example file
   - Screenshots of each step

4. **Customize the presentation**
   - Add institution-specific branding
   - Adjust examples for your TVET context
   - Modify timing based on your students' experience level

### 3. Materials to Share (24 hours before)

**Send to students:**

- [ ] Workshop agenda with clear timing
- [ ] List of accounts to create (with links)
- [ ] UNESCO AI Competency Framework document
- [ ] Pre-reading: "What are microcredentials?" (1-page brief)
- [ ] Technical requirements checklist
- [ ] Contact information for technical support

**Sample Email Template:**

```
Subject: Preparing for Tomorrow's Microcredential Creation Workshop

Dear Students,

Tomorrow we'll be creating our own UNESCO-aligned microcredential courses using AI tools. To ensure a smooth workshop, please complete these preparatory steps:

REQUIRED ACTIONS (30 minutes):
1. Create free accounts at:
   - Consensus AI: https://consensus.app
   - ChatGPT: https://chat.openai.com
   - Claude: https://claude.ai

2. Test LiaScript LiveEditor: https://liascript.github.io/LiveEditor/
   - Open the link and verify it loads properly

3. Review the UNESCO AI Competency Framework (attached)

4. Think about one specific learning need in your teaching context

TECHNICAL REQUIREMENTS:
- Computer with reliable internet
- Updated web browser (Chrome/Firefox/Edge)
- Ability to open multiple tabs/windows

OPTIONAL:
- Create a GitHub account (for permanent hosting)
- Review the pre-reading on microcredentials (attached)

Questions? Reply to this email or contact [support contact].

See you tomorrow!
[Your name]
```

### 4. Room/Environment Setup (day of workshop)

**Physical/Virtual Setup:**

- [ ] Reliable internet connection tested
- [ ] Projector/screen sharing working
- [ ] Student computers/devices functional
- [ ] Backup plan if internet fails (offline materials)
- [ ] Breakout rooms configured (if virtual)
- [ ] Recording enabled (if recording session)

**Materials Ready:**

- [ ] Workshop slide deck loaded
- [ ] Example files accessible
- [ ] Troubleshooting guide printed/accessible
- [ ] Timer or clock visible
- [ ] Whiteboard/digital whiteboard ready

---

## Detailed Step-by-Step Instructions

### STEP 1: Select UNESCO Learning Objective (10 minutes)

**Facilitator Actions:**

1. **Introduction (3 min)**
   ```
   - Welcome students
   - Brief overview of UNESCO Framework
   - Explain the three progression levels (Acquire, Deepen, Create)
   - Show the five competency areas
   ```

2. **Guided Selection (5 min)**
   ```
   - Display the UNESCO framework matrix (use slide)
   - Walk through 2 example selections with rationale
   - Prompt students to consider:
     * Their teaching context
     * Student needs they've observed
     * Their own developmental goals
   ```

3. **Individual Work (2 min)**
   ```
   - Students independently select their objective
   - Write it down with 2-3 sentence justification
   - Quick check: Raise hand when selected
   ```

**Sample Script:**

> "Let's start by selecting your learning objective. Look at this matrix - you have 15 possible objectives across five competency areas and three levels. For example, if you're new to AI in education, you might choose 'Understand basic AI ethical principles' at the Acquire level. If you're already using AI tools, you might select 'Apply human-centered principles in AI tool selection' at the Deepen level. Take two minutes now to select one objective that resonates with your current teaching context and write it down with a brief justification."

**Common Student Questions:**

| Question | Response |
|----------|----------|
| "Can I choose multiple objectives?" | "Focus on ONE for today. You can create additional modules later." |
| "What if I don't understand all the terms?" | "That's okay! Choose based on what resonates with you. We'll explore the concepts as we work." |
| "Should I choose an easy or challenging objective?" | "Choose what's relevant to your context. All levels are equally valid." |
| "Can I change my objective later?" | "Yes, but try to commit now so you can complete the full workflow today." |

**Checkpoint:**

- [ ] All students have selected one objective
- [ ] Objectives are written down
- [ ] A few students share their selections (2-3 volunteers)
- [ ] Move on when 80%+ have selected

**Troubleshooting:**

- **Issue:** Students overwhelmed by choices
  - **Solution:** Offer 3-4 pre-selected "recommended" objectives for beginners

- **Issue:** Students all choosing the same objective
  - **Solution:** Encourage diversity, but don't force it. Similar objectives can still yield different modules.

---

### STEP 2: Research with Consensus AI (20 minutes)

**Facilitator Actions:**

1. **Tool Introduction (3 min)**
   ```
   - Demonstrate Consensus AI interface
   - Show how to formulate search queries
   - Model one complete search example
   ```

2. **Live Demonstration (5 min)**
   ```
   - Take a sample objective: "Understand AI ethical principles"
   - Transform to search query: "What are main ethical issues in educational AI?"
   - Show search results
   - Demonstrate how to evaluate papers
   - Show how to extract key information
   ```

3. **Guided Practice (10 min)**
   ```
   - Students search for their own objectives
   - Walk around (physical) or monitor (virtual) for issues
   - Encourage students to try 2-3 different search queries
   - Prompt them to select 5-8 relevant papers
   ```

4. **Wrap-Up (2 min)**
   ```
   - Quick share: "Show of hands - who found at least 5 relevant papers?"
   - Address any major issues
   - Confirm everyone can proceed to next step
   ```

**Sample Script:**

> "Now we're going to research our topic using Consensus AI. This is different from Google - it searches specifically through academic papers and gives you evidence-based summaries. Watch as I demonstrate: I'm starting with a broad query 'AI ethics in education.' Notice how Consensus provides synthesis across multiple papers? Now I can dig deeper with 'bias in educational AI systems.' The key is to start broad, then narrow based on what you find. You have 10 minutes to find 5-8 papers relevant to your objective. Remember to note the key findings, not just collect papers."

**Sample Search Query Transformations:**

| UNESCO Objective | Effective Search Query |
|------------------|------------------------|
| "Understand basic AI ethical principles" | "What are ethical concerns with AI in education?" |
| "Apply human-centered principles in tool selection" | "What makes educational AI tools effective?" |
| "Design AI-enhanced experiences" | "How can AI support personalized learning?" |
| "Integrate AI tools into teaching practice" | "AI tools for formative assessment in classrooms" |
| "Analyze ethical implications of AI" | "What ethical frameworks guide educational AI use?" |

**Monitoring Student Progress:**

Check that students are:
- [ ] Actually searching (not stuck on account creation)
- [ ] Finding relevant papers (not getting irrelevant results)
- [ ] Recording key information (not just bookmarking)
- [ ] Moving beyond first search (iterating queries)
- [ ] Making progress (not perfectionism paralysis)

**Common Student Issues:**

| Issue | Symptoms | Solution |
|-------|----------|----------|
| Too narrow search | "I can't find anything!" | "Start broader - remove specific terms" |
| Too vague search | "I got 10,000 results!" | "Add discipline/context terms (TVET, higher ed)" |
| Perfectionism | Still searching after 15 min | "Select your top 5 now - you can add more later" |
| Off-topic results | Papers not matching objective | "Reformulate query - use more specific terms" |
| Technical issues | Can't access Consensus | Have backup option: Google Scholar with site filter |

**Checkpoint:**

- [ ] 80%+ of students have 3-5 relevant papers minimum
- [ ] Students have noted key findings from papers
- [ ] Any major technical issues resolved
- [ ] Ready to move to design phase

**Time Management:**

- If running over: "Everyone pause where you are. If you have 3+ papers, that's enough to proceed."
- If finishing early: "Great! Dig deeper into your top 2-3 papers. What specific data or examples could you use?"

---

### STEP 3: Design Outline with ChatGPT (25 minutes)

**Facilitator Actions:**

1. **Prompt Engineering Mini-Lesson (5 min)**
   ```
   - Explain the mega-prompt concept
   - Demonstrate structure: context, task, constraints, format
   - Show live example of prompt iteration
   - Explain why specificity matters
   ```

2. **Share Template (2 min)**
   ```
   - Provide the mega-prompt template (on slide or shared doc)
   - Walk through each section students need to fill
   - Emphasize customization, not just filling blanks
   ```

3. **Guided Creation (15 min)**
   ```
   - Students work on their prompts
   - Submit to ChatGPT
   - Review initial output
   - Iterate based on quality check
   - Aim for 2-3 iterations minimum
   ```

4. **Quality Check (3 min)**
   ```
   - Share quality criteria checklist
   - Students self-assess their outlines
   - Address common gaps (time estimates, activities, assessments)
   ```

**Sample Script:**

> "Now we're going to design our course outline using ChatGPT. The key to getting good output is giving ChatGPT excellent input - this is called prompt engineering. I'm going to show you a mega-prompt template that includes everything ChatGPT needs to create a quality outline. Notice how it specifies the learning objective, target audience, duration, pedagogical approach, and even includes research findings? Watch as I submit this and see what comes back. [Pause for demo] Good start, but I need to make it more specific to TVET contexts. So I'm going to add: 'Can you add more workplace-authentic examples and hands-on activities?' This is the iterative process - you rarely get perfect output on the first try."

**The Mega-Prompt Template (Display on screen):**

```markdown
I need your help designing a self-paced microcredential learning module. Here are the specifications:

**LEARNING OBJECTIVE:** 
[Your UNESCO objective - be specific]

**TARGET AUDIENCE:**
[Who are your learners? Level, context, prior knowledge]

**DURATION:** 
30-45 minutes

**DELIVERY FORMAT:**
Interactive LiaScript presentation for self-paced learning

**RESEARCH FINDINGS:**
[Paste 2-3 key findings from Consensus AI - actual findings, not just citations]

**PEDAGOGICAL APPROACH:**
Adult learning principles with constructivist methods

---

Please create a detailed course outline with:

1. **Module Title** - Engaging and descriptive

2. **Learning Outcomes** (3-4 specific, measurable outcomes using Bloom's taxonomy)

3. **Module Structure** with:
   - Section titles
   - Time allocation per section
   - Content summary
   - Planned activities (varied: video, reading, interactive, reflection)
   - Assessment checkpoints

4. **Assessment Strategy**:
   - 2-3 formative assessment activities
   - 1 summative assessment
   - Clear success criteria

5. **Resource List**:
   - Required readings/videos
   - Supplementary materials
   - Tools/platforms needed

6. **Differentiation Strategies**:
   - Options for different learning paces
   - Extension activities for advanced learners
   - Support scaffolding for struggling learners

Format the outline clearly with sections and subsections. Ensure adult learning principles are evident throughout (relevance, self-direction, experience-based, problem-centered).
```

**Iteration Prompts to Share:**

After initial output, students should ask ChatGPT:

1. "Can you add more specific examples relevant to [their TVET field]?"
2. "How can I make the activities more interactive and hands-on?"
3. "What multimedia elements would enhance engagement for adult learners?"
4. "Can you suggest more varied assessment types beyond quizzes?"
5. "How should I sequence this content for optimal knowledge progression?"

**Quality Checklist (Share with students):**

```markdown
Your outline should have:
- [ ] Clear module title (engaging, descriptive)
- [ ] 3-4 measurable learning outcomes
- [ ] 3-5 main sections with time estimates
- [ ] Mix of content types (not just text)
- [ ] At least 3 interactive elements
- [ ] Formative assessments throughout
- [ ] One summative assessment
- [ ] Realistic time allocations (total = 30-45 min)
- [ ] TVET-specific examples and context
- [ ] Differentiation strategies mentioned
```

**Monitoring Progress:**

Walk around or check screens to see:
- [ ] Students have submitted their prompt
- [ ] ChatGPT has responded with structured outline
- [ ] Students are reading the output critically
- [ ] Students are iterating (not just accepting first output)
- [ ] Outlines are realistic in scope and time

**Common Issues:**

| Issue | How to Identify | Solution |
|-------|-----------------|----------|
| Outline too ambitious | 60+ min of content listed | "Cut it in half. Pick your most essential 3 sections." |
| Too generic | No TVET-specific content | "Add iteration prompt: 'Make all examples relevant to [field]'" |
| Missing assessments | No quizzes or activities | "Add: 'Include 3 formative checks and 1 final assessment'" |
| Passive learning | All content is reading/watching | "Request: 'Add hands-on activities and reflection prompts'" |
| Poor time estimates | Unrealistic (5 min to learn complex concept) | "Ask ChatGPT to be more realistic about timing" |

**If Students Get Stuck:**

> "Raise your hand if ChatGPT's first output wasn't quite what you needed. That's normal! This is where the 'chat' part comes in. Tell ChatGPT specifically what to change. For example: 'This is too theoretical. Can you add practical, hands-on activities relevant to automotive repair training?'"

**Checkpoint Before Moving On:**

- [ ] All students have a structured outline
- [ ] Outlines include learning outcomes, sections, activities, assessments
- [ ] Time allocations are reasonable
- [ ] Content is relevant to students' objectives
- [ ] Students feel confident to move to build phase

**Time Management:**

- **If ahead of schedule:** "Great! Take 5 extra minutes to refine your outline. Think about what multimedia resources you'll need."
- **If behind schedule:** "We need to move on in 3 minutes. If your outline isn't perfect, that's okay - you'll refine it in the next step."

---

### STEP 4: Build with Claude (35 minutes)

**Facilitator Actions:**

1. **LiaScript Introduction (5 min)**
   ```
   - Quick overview of LiaScript capabilities
   - Show example of finished module
   - Demonstrate key syntax elements
   - Explain why we're using Claude (excellent markdown generation)
   ```

2. **Provide Build Prompt (3 min)**
   ```
   - Share the LiaScript mega-prompt template
   - Explain customization points
   - Show where to paste their outline
   - Demonstrate prompt submission
   ```

3. **Build Time (22 min)**
   ```
   - Students work with Claude to generate LiaScript
   - Monitor for common issues
   - Provide one-on-one support as needed
   - Encourage iteration and refinement
   ```

4. **Syntax Check (5 min)**
   ```
   - Students paste output into LiveEditor
   - Quick test of major functions
   - Note any syntax errors to fix
   ```

**Sample Script:**

> "Now we're moving from outline to actual interactive presentation using LiaScript. LiaScript is a markdown-based format that creates beautiful, interactive learning modules. The reason we're using Claude for this step is that Claude has excellent markdown skills and understands LiaScript syntax well. I'm going to show you the prompt to use, then you'll paste your ChatGPT outline into Claude along with this prompt. Claude will transform it into a complete LiaScript file. But remember - this is still collaborative. You'll need to review Claude's output, test it, and refine it."

**The LiaScript Build Prompt (Share with students):**

```markdown
I need you to transform my course outline into a complete LiaScript presentation. Here's what I have:

**MY COURSE OUTLINE:**
[Paste full ChatGPT outline here]

**RESEARCH SOURCES:**
[Paste 3-5 key citations from Consensus AI]

**TARGET FORMAT:**
A professional, interactive LiaScript presentation suitable for self-paced learning in a TVET context.

---

Please create a complete LiaScript markdown file with:

## 1. HEADER SECTION
- Proper metadata (author: [your name], version: 1.0.0, language: en, narrator: UK English Female)
- Custom CSS styling for professional appearance
- Clear comment description

## 2. MAIN CONTENT STRUCTURE
- Transform each outline section into separate LiaScript slides (use --- for breaks)
- Add voice narration text with --{{0}}-- notation for key sections
- Include section numbering and clear headings
- Proper hierarchy (# for title, ## for sections, ### for subsections)

## 3. MULTIMEDIA INTEGRATION
- Suggest relevant YouTube videos with !?[Title](URL) syntax
- Add placeholder images with proper attribution notes
- Include diagrams or visual aids where helpful

## 4. INTERACTIVE ELEMENTS
- Create multiple choice quizzes using LiaScript syntax:
  [( )] Wrong answer
  [(X)] Correct answer
- Add text input questions using [[solution]] syntax
- Include reflection prompts with text areas
- Add at least 3-5 interactive elements total

## 5. STYLING & VISUAL DESIGN
- Use custom div classes for:
  - Learning objectives boxes (class: framework-card)
  - Case study highlights (class: case-study)
  - Warning/tip boxes (class: warning-box)
  - Key takeaway sections (class: highlight)
- Apply color coding for different element types
- Ensure professional, clean appearance

## 6. ACCESSIBILITY
- Alt text for all images (descriptive)
- Closed caption notes for videos
- Clear heading hierarchy (proper H1, H2, H3 usage)
- Sufficient contrast in color choices
- Simple, readable language

## 7. CITATIONS & RESOURCES
- Create a "References" section at the end
- Format citations properly (APA or MLA style)
- Include working links to sources
- Add "Additional Resources" section

## SPECIFIC REQUIREMENTS:
- Use UK English narrator for voice
- Include estimated time for each major section
- Ensure mobile-responsive design (avoid complex tables)
- Add a "Quick Navigation" or table of contents at start
- Total module should be 30-45 minutes of learner time

Please generate the complete markdown file, starting with the header block (enclosed in <!-- -->) and ending with references. The file should be ready to paste directly into LiaScript LiveEditor.
```

**Key Points to Emphasize:**

1. **Claude is helping, not replacing you**
   - Review every section
   - Add your expertise and examples
   - Don't accept generic content

2. **Iteration is expected**
   - First output won't be perfect
   - Ask Claude to refine specific sections
   - Request different approaches if needed

3. **Focus on essentials first**
   - Get the structure right
   - Add basic interactivity
   - Polish later if time permits

**Common Claude Interaction Patterns:**

| Student Need | Follow-up Prompt |
|--------------|------------------|
| More specific examples | "Can you replace the generic examples with specific scenarios from [field]?" |
| Better quiz questions | "Make these quiz questions more application-based and challenging" |
| Add interactivity | "Add more hands-on activities and reflection prompts throughout" |
| Visual improvement | "Enhance the visual design with more custom styling and structure" |
| Simplify | "This is too complex. Simplify the language and structure" |

**Monitoring During Build Phase:**

Check that students are:
- [ ] Successfully getting output from Claude
- [ ] Reviewing the output (not just copying blindly)
- [ ] Asking follow-up questions to refine
- [ ] Making personal additions (examples, context)
- [ ] Testing output in LiveEditor periodically

**Troubleshooting Common Issues:**

**Issue: "Claude's output is too generic"**
```
Solution Prompt: "This is too generic. Add specific examples relevant to [automotive repair/nursing/welding/etc.] and use realistic workplace scenarios."
```

**Issue: "The quizzes are too easy"**
```
Solution Prompt: "Make these quiz questions more challenging. They should require application and analysis, not just recall. Use realistic scenarios from [field]."
```

**Issue: "Too much text, not enough interaction"**
```
Solution Prompt: "Break up the text-heavy sections. Add interactive elements like:
- Reflection questions with text input
- Scenario-based decision points
- Practice activities
- Visual diagrams
Aim for an interactive element every 5 minutes of content."
```

**Issue: "The structure is confusing"**
```
Solution Prompt: "Reorganize this to have a clearer logical flow:
1. Introduction with hooks
2. Foundation concepts
3. Application/practice
4. Assessment
5. Summary
Each section should have clear boundaries and transitions."
```

**Issue: "Citations are missing or wrong"**
```
Solution Prompt: "Add a proper References section at the end with APA citations for:
[paste your Consensus AI sources]
Also add in-text citations where you reference these sources."
```

**Quick LiaScript Syntax Reference (Share):**

```markdown
# Main Title (appears once at top)
## Section Heading (new slide)
### Subsection (within same slide)

--- (slide break)

!?[Video Title](YouTube URL)   ‚Üê embeds video

![Image alt text](image URL)   ‚Üê adds image

[( )] Wrong answer             ‚Üê multiple choice
[(X)] Correct answer

[[solution text]]              ‚Üê text input question

    --{{0}}--                   ‚Üê voice narration
Narration text here

<div class="highlight">         ‚Üê custom styled box
Content
</div>
```

**Checkpoint at 20-minute mark:**

Ask students to raise hand to indicate progress:
- ‚úã "Got complete markdown from Claude" - Most should have this
- ‚úã "Tested in LiveEditor and it loads" - Some should have this
- ‚úã "Made refinements and additions" - A few might have this

**If Many Students Are Stuck:**

Call a brief pause and do a live demonstration:
1. Show your screen
2. Take a sample outline
3. Submit to Claude with prompt
4. Show the output
5. Paste into LiveEditor
6. Show it working
7. Demonstrate one refinement iteration

**Time Warning at 30 minutes:**

> "You have 5 minutes left in the build phase. Your goal is to have a working LiaScript file that loads in LiveEditor. It doesn't need to be perfect - you'll refine it in the next step. If you're still iterating with Claude, accept what you have now and move to testing."

**Before Moving to Step 5:**

- [ ] All students have markdown file from Claude
- [ ] Most students have tested in LiveEditor
- [ ] Major structural issues resolved
- [ ] Students understand they'll continue refining

---

### STEP 5: Test & Deploy (15 minutes)

**Facilitator Actions:**

1. **Testing Protocol Introduction (3 min)**
   ```
   - Open LiveEditor for whole class to see
   - Demonstrate the testing checklist
   - Show how to identify and fix common issues
   - Explain the deployment options
   ```

2. **Systematic Testing (8 min)**
   ```
   - Students test each component methodically
   - Use the testing checklist
   - Fix issues as they're identified
   - Document anything that doesn't work
   ```

3. **Deployment Choice (2 min)**
   ```
   - Explain GitHub vs. direct link options
   - Help students choose based on their needs
   - Assist with deployment process
   ```

4. **Final Polish (2 min)**
   ```
   - Last-minute adjustments
   - Save final version
   - Confirm deployment successful
   ```

**Sample Script:**

> "Now we test! Testing is crucial - you want to catch issues before learners do. Open LiaScript LiveEditor and paste your complete markdown. Does it load? Good start. Now we're going to systematically check each component using this checklist. Don't just click through - actually interact with your quizzes, play your videos, and check that images load. Think like a learner: Is this clear? Does it work? Is it engaging?"

**The Testing Checklist (Display & Share):**

```markdown
## Component Testing Checklist

### Navigation
- [ ] Can you move between slides smoothly?
- [ ] Are slide breaks (---) in the right places?
- [ ] Does the structure make logical sense?

### Multimedia  
- [ ] Do all images load and display?
- [ ] Do videos embed and play correctly?
- [ ] Are images appropriately sized?

### Interactive Elements
- [ ] Do multiple choice questions work?
- [ ] Do text input questions accept answers?
- [ ] Does feedback display correctly?
- [ ] Are there enough interactive moments?

### Readability
- [ ] Is the text clear and readable?
- [ ] Is font size appropriate?
- [ ] Do headings stand out properly?
- [ ] Is there good use of white space?

### Styling
- [ ] Do custom div classes display correctly?
- [ ] Are colors appropriate and high contrast?
- [ ] Does it look professional?
- [ ] Does it work on mobile? (test in responsive mode)

### Content
- [ ] Are learning objectives clear?
- [ ] Does content match objectives?
- [ ] Is TVET context evident?
- [ ] Are examples specific and relevant?

### Completeness
- [ ] All sections from outline present?
- [ ] Assessment included?
- [ ] References formatted?
- [ ] Contact info provided?
```

**Live Debugging Demonstration:**

Show 2-3 common issues and how to fix them:

**Issue 1: Quiz Not Working**
```markdown
‚ùå WRONG:
[(x)] Correct answer  ‚Üê lowercase x doesn't work

‚úÖ CORRECT:
[(X)] Correct answer  ‚Üê capital X is required
```

**Issue 2: Image Not Loading**
```markdown
‚ùå WRONG:
![My image](image.jpg)  ‚Üê local file path won't work online

‚úÖ CORRECT:
![My image](https://full-url-to-image.jpg)  ‚Üê needs full URL
```

**Issue 3: Voice Narration Not Showing**
```markdown
‚ùå WRONG:
--{{0}}--
Text here

‚úÖ CORRECT:
    --{{0}}--    ‚Üê needs 4 spaces indent
Text here
```

**Deployment Options Explained:**

**Option 1: GitHub (Recommended for long-term)**

Advantages:
- ‚úÖ Permanent, professional URL
- ‚úÖ Version control
- ‚úÖ Easy updates
- ‚úÖ Can collaborate with others

Steps:
1. Create GitHub repository
2. Upload .md file
3. Get raw URL
4. Share: `https://liascript.github.io/course/?[RAW_URL]`

**Option 2: Direct Link (Quick share)**

Advantages:
- ‚úÖ Instant, no setup
- ‚úÖ Great for testing

Steps:
1. Click "Share" in LiveEditor
2. Copy link
3. Share with learners

Disadvantages:
- ‚ö†Ô∏è Link may expire
- ‚ö†Ô∏è Can't track versions

**For Students With Limited Time:**

> "If you don't have time for GitHub setup now, use the direct link to share your work today. You can move it to GitHub later for permanent hosting."

**Quick GitHub Setup Guide (if time allows):**

```
1. Go to github.com
2. Sign in
3. Click "New" repository
4. Name it (e.g., "ai-ethics-microcredential")
5. Make it Public
6. Click "Create repository"
7. Click "uploading an existing file"
8. Upload your .md file
9. Click "Commit"
10. Click on your file
11. Click "Raw" button
12. Copy that URL
13. Paste into: https://liascript.github.io/course/?[YOUR_RAW_URL]
14. Bookmark and share!
```

**Monitoring During Testing:**

Walk around/monitor to help with:
- [ ] Technical issues (images not loading, quizzes broken)
- [ ] Content problems (confusing sections)
- [ ] Deployment confusion (GitHub setup)
- [ ] Time management (students polishing forever)

**Common Testing Issues:**

| Student Says | Likely Problem | Quick Fix |
|--------------|----------------|-----------|
| "My quizzes don't work" | Syntax error | Check brackets: [(X)] vs [( )] |
| "Video won't embed" | Wrong URL format | Need full YouTube URL with !?[] |
| "It looks messy" | Styling issues | Check div tags are closed |
| "Images are huge" | No size specification | Add: <!-- width="400px" --> after image |
| "Can't find my file" | Not saved | Save to Downloads folder first |

**Checkpoint Before Final Step:**

- [ ] All students have working LiaScript presentation
- [ ] Most have tested key components
- [ ] Deployment method chosen
- [ ] Link is shareable (tested by opening in new tab)

**If Running Out of Time:**

> "We need to move to the documentation phase in 2 minutes. Make sure you have:
> 1. A link that works when you open it
> 2. Your markdown file saved
> 3. At least your main sections tested
> You can continue refining after the workshop."

---

### STEP 6: Document & Reflect (10 minutes)

**Facilitator Actions:**

1. **Introduce Reflection Purpose (2 min)**
   ```
   - Explain the importance of documenting AI usage
   - Connect to UNESCO competency development
   - Show the reflection template
   ```

2. **Guided Reflection (6 min)**
   ```
   - Students complete AI usage log
   - Answer reflection prompts
   - Self-assess UNESCO competencies
   ```

3. **Share & Debrief (2 min)**
   ```
   - 2-3 volunteers share one insight
   - Whole group reflection on the process
   - Connect back to learning objectives
   ```

**Sample Script:**

> "The final step is critical: documenting your process and reflecting on it. This isn't busy work - it's developing your critical AI literacy. As educators using AI to design learning, we need to be transparent about how AI influenced our decisions. We also need to critically examine what AI can and can't do. Take 6 minutes to complete your reflection using this template."

**Reflection Template (Share as document):**

```markdown
# AI-Assisted Design Process Reflection

## AI Tool Usage Log

| Tool | Purpose | What I Asked | Quality of Output (1-5) | What I Changed | Learning |
|------|---------|--------------|-------------------------|----------------|----------|
| Consensus AI | Research | [brief description] | [1-5] | [what you modified] | [what you learned] |
| ChatGPT | Outline design | [brief description] | [1-5] | [what you modified] | [what you learned] |
| Claude | LiaScript build | [brief description] | [1-5] | [what you modified] | [what you learned] |

## Reflection Questions

### 1. Pedagogical Decisions
How did AI tools influence your pedagogical decisions? What critical choices did YOU make that AI could not?

[2-3 sentences]

### 2. Efficiency vs. Quality
Where did AI accelerate your work? Where did you need to slow down and apply human judgment?

[2-3 sentences]

### 3. Ethical Considerations  
What ethical concerns emerged (if any) in using AI for design? How did you address them?

[2-3 sentences]

### 4. Learner Impact
How might your use of AI in the design process benefit your learners? Potential drawbacks?

[2-3 sentences]

### 5. UNESCO Competency Self-Assessment

Rate your own development through this process:

| Competency | My Level | Evidence from Today |
|------------|----------|---------------------|
| Human-Centered Mindset | ‚≠êÔ∏è Acquire / ‚≠êÔ∏è‚≠êÔ∏è Deepen / ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è Create | |
| Ethics of AI | ‚≠êÔ∏è Acquire / ‚≠êÔ∏è‚≠êÔ∏è Deepen / ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è Create | |
| AI Foundations | ‚≠êÔ∏è Acquire / ‚≠êÔ∏è‚≠êÔ∏è Deepen / ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è Create | |
| AI Pedagogy | ‚≠êÔ∏è Acquire / ‚≠êÔ∏è‚≠êÔ∏è Deepen / ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è Create | |
| Professional Learning | ‚≠êÔ∏è Acquire / ‚≠êÔ∏è‚≠êÔ∏è Deepen / ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è Create | |

### 6. Future Application
How will you use this workflow in future course development? What would you do differently?

[2-3 sentences]
```

**Guiding Questions for Deeper Reflection:**

Pose these to the whole group:

1. **"Did AI make you a better designer, or just a faster one?"**
   - Prompt thinking about quality vs. quantity

2. **"What surprised you about working with AI tools?"**
   - Reveal assumptions and learning moments

3. **"Where did you feel most in control? Least in control?"**
   - Explore agency and human role

4. **"If AI designed your course without you, would it be better or worse? Why?"**
   - Highlight irreplaceable human expertise

5. **"What does 'co-design' with AI really mean?"**
   - Deepen understanding of collaboration

**Group Debrief Format:**

**Popcorn Share (2 minutes):**
> "Turn to someone near you. Share one surprising thing you learned today about AI or about yourself as a designer. 60 seconds each."

**Whole Group (2 minutes):**
> "Who wants to share one insight from your reflection? What's one thing you'll take away from today?"

**Closing (1 minute):**
> "You've each created something valuable today - a learning module that didn't exist before. More importantly, you've developed critical competencies for working with AI as an educational designer. This is just the beginning. I encourage you to:
> 
> 1. Share your module with colleagues for feedback
> 2. Pilot it with learners
> 3. Iterate based on what you learn
> 4. Create more modules using this workflow
>
> Thank you for your engagement today!"

**Checkpoint:**

- [ ] Students have completed AI usage log
- [ ] Reflection prompts answered
- [ ] UNESCO self-assessment done
- [ ] Group sharing occurred
- [ ] Final questions addressed

---

## Troubleshooting Guide

### Technical Issues

**Issue: Student can't access Consensus AI**

- **Cause:** Might require institutional email for free tier
- **Solution 1:** Use personal email to create account
- **Solution 2:** Use Google Scholar as alternative
- **Prevention:** Have students create accounts before workshop

**Issue: ChatGPT says "At capacity"**

- **Cause:** High traffic on free tier
- **Solution 1:** Wait 5-10 minutes and retry
- **Solution 2:** Use Claude for outline design instead
- **Solution 3:** Have students work on refinement of previous step meanwhile

**Issue: Claude is slow to respond**

- **Cause:** Complex prompt, network issues, or service load
- **Solution 1:** Break prompt into smaller pieces
- **Solution 2:** Simplify the request
- **Solution 3:** Have students start with basic structure, add details later

**Issue: LiaScript LiveEditor won't load**

- **Cause:** Network restrictions, outdated browser, or service outage
- **Solution 1:** Try different browser (Chrome, Firefox, Edge)
- **Solution 2:** Check if institution firewall blocks the site
- **Solution 3:** Use alternative: https://liascript.github.io/ (main site)
- **Prevention:** Test all platforms from your institution's network beforehand

**Issue: GitHub upload fails**

- **Cause:** File format issue, size limit, or connection problem
- **Solution 1:** Ensure file is .md extension
- **Solution 2:** Check file size (should be small, mostly text)
- **Solution 3:** Copy/paste content into GitHub's web editor instead

### Pedagogical Issues

**Issue: Student's objective is too broad**

- **Symptoms:** Trying to teach "everything about AI ethics"
- **Solution:** "Let's narrow this. Pick ONE aspect of AI ethics - like bias detection or privacy concerns. You can create multiple modules later."

**Issue: Student's objective is too narrow**

- **Symptoms:** "Understand the definition of algorithmic bias"
- **Solution:** "That's too small for a 30-minute module. Can you expand to include examples, impact, and detection strategies?"

**Issue: Outline is all theory, no practice**

- **Symptoms:** Reading and videos only, no hands-on work
- **Solution:** "Adult learners need to DO something. Add:
  - Case study analysis
  - Decision-making scenarios
  - Tool exploration
  - Reflection on own practice"

**Issue: Module is too long**

- **Symptoms:** 90+ minutes of content
- **Solution:** "This is actually 2-3 modules. Pick your most essential 3 sections and save the rest for 'Module 2.'"

**Issue: No connection to TVET context**

- **Symptoms:** Generic examples, no workplace relevance
- **Solution:** "Every example should connect to real TVET work. Replace 'business scenario' with 'welding shop scenario' or 'healthcare clinic scenario.'"

### Process Issues

**Issue: Student is perfectionist and behind**

- **Symptoms:** Still refining Step 2 when others are on Step 4
- **Solution:** "Your goal today is DONE, not PERFECT. Move forward now with what you have. You can refine later."

**Issue: Student rushes and produces low quality**

- **Symptoms:** Finished in half the time, but output is bare minimum
- **Solution:** "Great progress! Now let's refine. [Show specific improvements needed]. Take 10 more minutes to enhance quality."

**Issue: Student is overwhelmed and shutting down**

- **Symptoms:** Not engaging, saying "I can't do this"
- **Solution:** 
  1. Break it down: "Just focus on this one step right now"
  2. Lower stakes: "This is practice. It doesn't have to be perfect"
  3. Provide template: "Start with this example and modify it"
  4. Partner them: "Work with [name] for this part"

**Issue: Technical skills vary widely**

- **Symptoms:** Some students fly ahead while others struggle with basics
- **Solution:**
  1. Create "fast track" for advanced students (extensions)
  2. Pair experienced students with struggling ones
  3. Have "checkpoint helpers" - students who finish early help others
  4. Provide differentiated support materials

### Content Issues

**Issue: AI generates biased or problematic content**

- **Symptoms:** Stereotypical examples, cultural insensitivity, etc.
- **Solution:** Use as teaching moment:
  - "What's problematic about this example?"
  - "How would you revise it?"
  - "This shows why human review is essential"
- **Prevention:** Emphasize critical review in instructions

**Issue: Citations are wrong or missing**

- **Symptoms:** Made-up references, incorrect formatting
- **Solution:** "Always verify citations against your Consensus AI sources. If you didn't read it, don't cite it."

**Issue: Content is too advanced/too simple for audience**

- **Symptoms:** Students report module is not right level
- **Solution:** "Revise with specific audience in mind:
  - Add prerequisites statement
  - Provide scaffolding OR extension activities
  - Adjust examples and language"

### Time Management Issues

**Issue: Running significantly behind schedule**

- **Solutions:**
  1. **Skip breakout activities** - move to large group
  2. **Assign homework** - complete documentation as homework
  3. **Compress Step 5** - test only major components
  4. **Extend session** - if possible, add 15-30 minutes

**Issue: Finishing too early**

- **Solutions:**
  1. **Deep dive refinement** - improve visual design, add more interactivity
  2. **Peer review** - students exchange modules and provide feedback
  3. **Extension activity** - start planning Module 2
  4. **Showcase** - students present their modules to class

---

## Assessment Rubric

Use this rubric for formal assessment of student work:

### Overall Assessment Categories

| Category | Weight | Criteria |
|----------|--------|----------|
| **UNESCO Alignment** | 20% | Learning objective selection and justification |
| **Research Quality** | 15% | Use of academic sources, integration of findings |
| **Instructional Design** | 25% | Pedagogical soundness, structure, progression |
| **Technical Execution** | 20% | LiaScript functionality, interactivity, polish |
| **Critical Reflection** | 20% | Depth of reflection, AI literacy awareness |

### Detailed Rubric

#### 1. UNESCO Alignment (20 points)

**Exemplary (18-20 points)**
- Learning objective is precisely selected from UNESCO framework
- Clear, compelling justification tied to specific teaching context
- Demonstrates deep understanding of progression levels
- Module content fully addresses the selected objective

**Proficient (15-17 points)**
- Learning objective appropriately selected
- Adequate justification provided
- Shows understanding of framework structure
- Module content mostly addresses objective

**Developing (12-14 points)**
- Learning objective selected but justification weak
- Limited understanding of framework levels
- Module content partially addresses objective

**Beginning (0-11 points)**
- Objective unclear or not from framework
- Weak or missing justification
- Module doesn't align with objective

#### 2. Research Quality (15 points)

**Exemplary (14-15 points)**
- 5-8 high-quality, recent academic sources from Consensus AI
- Sources directly relevant to learning objective
- Key findings integrated throughout module
- Proper citations in APA/MLA format

**Proficient (12-13 points)**
- 4-5 quality academic sources
- Sources generally relevant
- Some integration of findings
- Citations present with minor errors

**Developing (10-11 points)**
- 2-3 sources of varying quality
- Limited relevance to objective
- Minimal integration of findings
- Citation errors or inconsistencies

**Beginning (0-9 points)**
- Fewer than 2 sources or non-academic sources
- Poor relevance
- No integration of research
- Missing or incorrect citations

#### 3. Instructional Design (25 points)

**Exemplary (23-25 points)**
- Clear, measurable learning outcomes (Bloom's taxonomy)
- Logical content sequence with appropriate scaffolding
- Multiple varied activities (mix of passive and active)
- Authentic TVET examples throughout
- Appropriate pacing (30-45 minutes realistic)
- Adult learning principles evident
- Formative and summative assessment included
- Differentiation strategies present

**Proficient (20-22 points)**
- Clear learning outcomes
- Logical sequence
- Some varied activities
- TVET context evident
- Generally appropriate timing
- Assessment included
- Some differentiation

**Developing (17-19 points)**
- Learning outcomes present but not all measurable
- Sequence has gaps
- Limited activity variety
- Generic examples, weak TVET connection
- Timing unrealistic
- Basic assessment only
- Minimal differentiation

**Beginning (0-16 points)**
- Unclear learning outcomes
- Illogical sequence
- Passive learning only
- No TVET context
- Poor time estimates
- Weak or missing assessment
- No differentiation

#### 4. Technical Execution (20 points)

**Exemplary (18-20 points)**
- LiaScript syntax perfect throughout
- All multimedia loads and functions properly
- Interactive elements work correctly (quizzes, inputs)
- Professional visual design with custom styling
- Fully accessible (alt text, headings, contrast)
- Mobile-responsive
- No broken links or errors
- Deployed successfully with shareable link

**Proficient (15-17 points)**
- Mostly correct syntax
- Most multimedia functional
- Interactive elements work
- Good visual design
- Basic accessibility features
- Generally mobile-friendly
- Minor technical issues
- Successfully deployed

**Developing (12-14 points)**
- Some syntax errors
- Some multimedia issues
- Limited interactivity
- Basic visual design
- Limited accessibility
- Deployment successful but not polished

**Beginning (0-11 points)**
- Major syntax errors
- Multimedia mostly broken
- Interactivity doesn't work
- Poor visual design
- Inaccessible
- Deployment issues

#### 5. Critical Reflection (20 points)

**Exemplary (18-20 points)**
- Comprehensive AI usage log with detailed entries
- Deep reflection on all prompts with specific examples
- Critical awareness of AI capabilities and limitations
- Thoughtful analysis of ethical considerations
- Accurate UNESCO competency self-assessment with evidence
- Clear articulation of human vs. AI contributions
- Sophisticated understanding of AI as co-design tool

**Proficient (15-17 points)**
- Complete AI usage log
- Good reflection on most prompts
- Awareness of AI strengths and weaknesses
- Consideration of ethics
- Reasonable self-assessment
- Understands collaborative nature of AI design

**Developing (12-14 points)**
- Basic AI usage log
- Surface-level reflections
- Limited critical perspective
- Minimal ethical consideration
- Self-assessment present but not well-evidenced
- Unclear about human role

**Beginning (0-11 points)**
- Incomplete or missing log
- Shallow or missing reflections
- No critical awareness
- Ethics not addressed
- Self-assessment absent or inaccurate
- Doesn't understand co-design concept

### Quick Scoring Guide

**Total Points: 100**

- **90-100:** Exemplary work, publication-ready module
- **80-89:** Proficient work, ready for pilot testing
- **70-79:** Developing work, needs revision before use
- **Below 70:** Beginning work, significant revision needed

### Feedback Template

```
Student: _______________
Module Title: _______________
Total Score: ___/100

Strengths:
- [Specific positive feedback]
- [Specific positive feedback]

Areas for Improvement:
- [Specific constructive feedback with suggestions]
- [Specific constructive feedback with suggestions]

Next Steps:
1. [Concrete action student should take]
2. [Concrete action student should take]

Overall Comments:
[Holistic feedback on the learning journey and growth]
```

---

## Extension Activities

For students who finish early or want to go deeper:

### Extension 1: Peer Review Protocol

**Time:** 15 minutes

**Instructions:**
1. Exchange module links with a partner
2. Complete the module as a learner would
3. Provide structured feedback using this template:

```markdown
## Peer Review Feedback

**Module Title:** _______________
**Reviewer:** _______________

### Strengths (3 things that worked well):
1.
2.
3.

### Questions/Confusion (2 things that were unclear):
1.
2.

### Suggestions (3 specific improvements):
1.
2.
3.

### Overall Impression:
Rate: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (1-5 stars)

Brief comment:
```

### Extension 2: Module Series Planning

**Time:** 20 minutes

**Task:** Plan a 3-module microcredential series

**Instructions:**
1. Your current module is Module 1
2. Design Module 2 and 3 to build on it
3. Map progression:
   - Module 1 (today): [Learning objective]
   - Module 2: [Next level objective]
   - Module 3: [Advanced objective]
4. Create outline for Module 2

**Template:**
```markdown
## Microcredential Series: [Title]

**Series Goal:** [What will learners be able to do after all 3 modules?]

### Module 1 (Complete): [Title]
- Objective: [UNESCO objective]
- Duration: 30-45 min
- Level: [Acquire/Deepen/Create]

### Module 2 (Outline): [Title]
- Objective: [UNESCO objective - builds on Module 1]
- Duration: 30-45 min  
- Level: [Next progression level]
- Key Topics:
  1.
  2.
  3.
- New Skills:
  -
  -

### Module 3 (Plan): [Title]
- Objective: [UNESCO objective - highest level]
- Duration: 30-45 min
- Level: [Create level preferred]
- Capstone Project: [Description]
```

### Extension 3: Badge Design

**Time:** 20 minutes

**Task:** Design a digital badge for your microcredential

**Instructions:**
1. Use free tool: Canva, Adobe Express, or BadgeCraft
2. Include:
   - Module title
   - Key competency achieved
   - Visual that represents the learning
   - UNESCO framework reference
3. Create metadata:
   - Badge name
   - Description
   - Criteria for earning
   - Skills represented

**Badge Metadata Template:**
```markdown
## Digital Badge Design

**Badge Name:** _______________

**Visual Description:** 
[Describe the visual elements and what they represent]

**Badge Description (50 words):**
[What does earning this badge mean?]

**Criteria for Earning:**
- [ ] Complete all module sections
- [ ] Score 80%+ on assessment
- [ ] Submit reflection
- [ ] [Add criterion]

**Skills/Competencies:**
- [Skill 1]
- [Skill 2]
- [Skill 3]

**UNESCO Alignment:**
[Which framework area and level?]

**Issuer:** [Your institution]

**Validity:** [Does it expire? Need renewal?]
```

### Extension 4: Accessibility Audit

**Time:** 15 minutes

**Task:** Audit your module for accessibility

**Checklist:**
```markdown
## Accessibility Audit

### Visual Accessibility
- [ ] All images have descriptive alt text
- [ ] Color contrast meets WCAG AA standards (4.5:1 minimum)
- [ ] Text is readable at 200% zoom
- [ ] Color is not the only way to convey information
- [ ] Heading hierarchy is logical (H1 > H2 > H3)

### Auditory Accessibility
- [ ] Videos have captions or transcripts noted
- [ ] Voice narration is optional, not required
- [ ] Audio content has text alternative

### Navigation Accessibility
- [ ] Keyboard navigation works (Tab, Enter, Arrow keys)
- [ ] Skip navigation option available
- [ ] Clear section breaks and structure
- [ ] Table of contents or progress indicator present

### Cognitive Accessibility  
- [ ] Language is clear and simple (appropriate reading level)
- [ ] Content is chunked into manageable sections
- [ ] White space used effectively
- [ ] Consistent layout and design
- [ ] Instructions are clear and explicit

### Motor Accessibility
- [ ] Click targets are large enough (44px minimum)
- [ ] No time limits on interactions
- [ ] Alternatives to drag-and-drop if used

**Issues Found:** [List with priority]

**Fixes Implemented:** [What you changed]
```

### Extension 5: Learning Analytics Plan

**Time:** 15 minutes

**Task:** Design how you'll measure module effectiveness

**Template:**
```markdown
## Learning Analytics & Evaluation Plan

### Data to Collect

**Quantitative Metrics:**
- [ ] Completion rate (% who finish)
- [ ] Time spent (average duration)
- [ ] Quiz scores (per question and overall)
- [ ] Interaction rate (% who engage with activities)
- [ ] Drop-off points (where learners exit)

**Qualitative Feedback:**
- [ ] End-of-module survey (satisfaction, clarity, usefulness)
- [ ] Open-ended comments
- [ ] Most/least helpful sections
- [ ] Technical issues reported

### Evaluation Questions

1. **Effectiveness:** Did learners achieve the learning outcomes?
   - Measure: [How will you measure this?]

2. **Engagement:** Were learners actively engaged?
   - Measure: [How will you measure this?]

3. **Satisfaction:** Did learners find it valuable?
   - Measure: [How will you measure this?]

4. **Transfer:** Can learners apply this in their context?
   - Measure: [Follow-up survey/observation]

### Improvement Plan

Based on pilot data, I will:
- If completion rate < 70%: [Action]
- If quiz scores < 80% average: [Action]
- If satisfaction < 4/5: [Action]
- If [other criterion]: [Action]

### Timeline

- Week 1: Pilot with 10-15 learners
- Week 2: Collect and analyze data
- Week 3: Make revisions
- Week 4: Launch revised version
- Ongoing: Quarterly reviews and updates
```

---

## Resources & Links

### Essential Workshop Links

**AI Tools:**
- Consensus AI: https://consensus.app
- ChatGPT: https://chat.openai.com
- Claude: https://claude.ai

**LiaScript:**
- LiveEditor: https://liascript.github.io/LiveEditor/
- Official Documentation: https://liascript.github.io/course/
- GitHub Repository: https://github.com/LiaScript/docs
- Community: https://gitter.im/LiaScript/community

**Deployment:**
- GitHub: https://github.com
- LiaScript Course Viewer: https://liascript.github.io/course/

### UNESCO & Framework Resources

- UNESCO AI Competency Framework for Teachers (2024): https://www.unesco.org/en/digital-education/ai-future-learning
- UNESCO AI and Education Guidance: https://www.unesco.org/en/articles/artificial-intelligence-education-guidance-policy-makers
- Beijing Consensus on AI and Education: https://www.unesco.org/en/articles/beijing-consensus-artificial-intelligence-and-education

### Microcredential Standards

- European Commission Microcredential Recommendation: https://europa.eu/europass/en/europass-tools/european-digital-credentials
- UNESCO-UNEVOC TVET Resources: https://unevoc.unesco.org/
- Digital Credentials Consortium: https://digitalcredentials.mit.edu/

### Additional Tools & Platforms

**Alternative AI Tools:**
- Perplexity AI: https://perplexity.ai (research)
- Anthropic Claude: https://claude.ai (content generation)
- Microsoft Copilot: https://copilot.microsoft.com

**Multimedia Resources:**
- YouTube (with Creative Commons filter): https://www.youtube.com/creativecommons
- Wikimedia Commons: https://commons.wikimedia.org
- Unsplash: https://unsplash.com (free images)
- Pexels: https://www.pexels.com (free images/videos)

**Design Tools:**
- Canva: https://www.canva.com (graphics, badges)
- Adobe Express: https://www.adobe.com/express (design)
- Excalidraw: https://excalidraw.com (diagrams)

### Pedagogical Resources

**Instructional Design:**
- Bloom's Taxonomy: https://cft.vanderbilt.edu/guides-sub-pages/blooms-taxonomy/
- Adult Learning Principles: https://lincs.ed.gov/state-resources/federal-initiatives/teal/guide/adultlearning
- TVET Pedagogy: UNESCO-UNEVOC resources

**AI in Education:**
- AI for Education: https://www.aiforeducation.io
- Teaching AI: https://www.teachingai.org
- ISTE AI Standards: https://www.iste.org/ai

### Community & Support

**LiaScript Community:**
- Discord/Gitter: https://gitter.im/LiaScript/community
- GitHub Discussions: https://github.com/LiaScript/LiaScript/discussions
- Example Courses: https://github.com/LiaScript/docs/tree/master/examples

**Professional Networks:**
- TVET Communities (UNESCO-UNEVOC)
- EdTech LinkedIn Groups
- Open Education Resources Commons

### Recommended Reading

1. **UNESCO. (2024).** *AI Competency Framework for Teachers: A guide for policy-makers and teacher educators.*

2. **Delgado Kloos, C., et al. (2025).** "How Challenges Become Opportunities: Micro-credentials and Artificial Intelligence." *IEEE EDUCON Conference.*

3. **Holstein, K., et al. (2019).** "Student Learning Benefits of a Mixed-Reality Teacher Awareness Tool in AI-Enhanced Classrooms." *AIED 2019.*

4. **Luckin, R., et al. (2016).** *Intelligence Unleashed: An argument for AI in Education.* Pearson.

5. **Zawacki-Richter, O., et al. (2019).** "Systematic review of research on artificial intelligence applications in higher education ‚Äì where are the educators?" *International Journal of Educational Technology in Higher Education.*

### Sample Modules

Access example microcredential modules created with this workflow:

1. **AI Ethics Foundations** (Acquire level)
   - Link: [To be added - example module]
   
2. **Evaluating AI Tools for TVET** (Deepen level)
   - Link: [To be added - example module]

3. **Designing AI-Enhanced Learning** (Create level)
   - Link: [To be added - example module]

---

## Workshop Checklist

### One Week Before

- [ ] Workshop venue/virtual room booked
- [ ] Materials prepared and tested
- [ ] Student accounts verified
- [ ] Example modules completed
- [ ] Email sent to students with prep instructions
- [ ] Technical support on standby
- [ ] Backup plan prepared for tech failures

### One Day Before

- [ ] Test all tools from venue/platform
- [ ] Verify internet connectivity
- [ ] Print/prepare handouts (if physical)
- [ ] Load presentation and examples
- [ ] Configure breakout rooms (if virtual)
- [ ] Charge all devices
- [ ] Prepare timer/clock

### Day Of - 30 Minutes Before

- [ ] Arrive early/log in early
- [ ] Test projector/screen sharing
- [ ] Test audio/microphone
- [ ] Open all necessary tabs/windows
- [ ] Prepare whiteboard/digital whiteboard
- [ ] Welcome students as they arrive
- [ ] Final tech check

### During Workshop

- [ ] Take attendance
- [ ] Record session (if permitted and announced)
- [ ] Monitor time at each step
- [ ] Check in with struggling students
- [ ] Document interesting questions/issues
- [ ] Collect informal feedback

### After Workshop

- [ ] Thank participants
- [ ] Share recording (if made)
- [ ] Send follow-up email with resources
- [ ] Collect formal feedback (survey)
- [ ] Document lessons learned
- [ ] Update materials based on experience
- [ ] Plan follow-up support session

---

## Facilitator Self-Reflection

After conducting the workshop, reflect on your facilitation:

### What Went Well?

- What timing worked perfectly?
- Which activities were most engaging?
- What explanations were clearest?
- Which student questions led to great learning?

### What Needs Improvement?

- Where did students struggle most?
- What timing needs adjustment?
- Which instructions were confusing?
- What technical issues occurred?

### Changes for Next Time:

1. [Specific change]
2. [Specific change]
3. [Specific change]

### Student Feedback Themes:

- [Common positive feedback]
- [Common improvement suggestion]
- [Unexpected insight]

---

## Contact & Support

**Workshop Developers:**

- **Prof. Dr. Tina Haase**
  - IFF Fraunhofer Magdeburg
  - [Contact information]

- **Hannes Dettmann**
  - Otto von Guericke Universit√§t Magdeburg
  - Email: hannes.dettmann@ovgu.de

**For Technical Support:**

- LiaScript issues: https://github.com/LiaScript/LiaScript/issues
- Workshop questions: [Your contact email]
- AI tool troubleshooting: Check individual platform support pages

---

## License & Attribution

This workshop guide is released under **Creative Commons Attribution 4.0 International (CC BY 4.0)**

You are free to:
- **Share** ‚Äî copy and redistribute the material
- **Adapt** ‚Äî remix, transform, and build upon the material

Under these terms:
- **Attribution** ‚Äî Give appropriate credit and link to license

**Suggested Citation:**

> Haase, T., & Dettmann, H. (2024). *Microcredential Creation Workshop: UNESCO-Aligned AI-Enhanced Course Design.* Otto von Guericke Universit√§t Magdeburg & IFF Fraunhofer. CC BY 4.0.

---

**End of Instructor Walkthrough**

*Version 1.0.0 | December 2024*

**Questions or suggestions for improving this guide?**  
Contact: hannes.dettmann@ovgu.de
